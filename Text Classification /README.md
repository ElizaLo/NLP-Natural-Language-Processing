# Text Classification

- [Text Classification: Best Practices for Real World Applications](https://kavita-ganesan.com/practical-text-classification-best-practices/#.YGMTSy1c5WM)
- [Классифицируйте текст с помощью BERT](https://www.tensorflow.org/tutorials/text/classify_text_with_bert)

## Multi-Label, Multi-Class Text Classification

- [Multi-Label, Multi-Class Text Classification with BERT, Transformers and Keras](https://towardsdatascience.com/multi-label-multi-class-text-classification-with-bert-transformer-and-keras-c6355eccb63a)
- [Building a Multi-label Text Classifier using BERT and TensorFlow](https://towardsdatascience.com/building-a-multi-label-text-classifier-using-bert-and-tensorflow-f188e0ecdc5d)
- [Multi Class Text Classification With Deep Learning Using BERT](https://towardsdatascience.com/multi-class-text-classification-with-deep-learning-using-bert-b59ca2f5c613)
- [Как использовать BERT для мультиклассовой классификации текста](https://neurohive.io/ru/tutorial/bert-klassifikacya-teksta/)
- [How to solve Multi-Class Classification Problems in Deep Learning with Tensorflow & Keras?](https://medium.com/deep-learning-with-keras/which-activation-loss-functions-in-multi-class-clasification-4cd599e4e61f)
- [Multiclass Text Classification From Start To Finish](https://medium.com/@robert.salgado/multiclass-text-classification-from-start-to-finish-f616a8642538)

| Title | Description, Information |
| :---:         |          :--- |
|[Bert multi-label text classification by PyTorch](https://github.com/lonePatient/Bert-Multi-Label-Text-Classification)|This repo contains a PyTorch implementation of a pretrained BERT model for multi-label text classification.|


## Ready solutions from the AWS

| Title | Description, Information |
| :---:         |          :--- |
|[Amazon Comprehend](https://aws.amazon.com/comprehend/)|Uncover valuable insights from text in documents, customer support tickets, product reviews, emails, social media feeds, and more. Simplify document processing workflows by extracting text, key phrases, topics, sentiment, and more from documents such as insurance claims.|
|[Explainable AI for Text Classification](https://aws.amazon.com/marketplace/pp/prodview-xolgpdp52ke44)|The solution applies deep learning model (CNN) to classify text data such as reviews and transcripts to identify features leading to prediction of user defined classes. It has explainable AI functionality which helps to understand why the model predicts the class based on key words and phrases in the text. The solution is adaptable and can be trained on any textual dataset containing user defined classes.|
|[Text Classification API](https://aws.amazon.com/marketplace/pp/prodview-ztfazwmcw7pxc)|When given text, this API classifies and recommends highly related categories for e-commerce and other uses. Text classification can be used to automatically categorize many articles and texts into our default categories. Enterprise customers can create their own predefined categories. Contact support for more info.|

--------------------
- [5 Data Augmentation Techniques for Text Classification](https://saurabhk30.medium.com/5-data-augmentation-techniques-for-text-classification-d14f6d8bd6aa)


## Few-Shot Text Classification

- [Few-Shot Text Classification](https://paperswithcode.com/task/few-shot-text-classification#code) on Papers With Code
- [Few-Shot Text Classification](https://few-shot-text-classification.fastforwardlabs.com)

### Models

| Title | Description, Information |
| :---:         |          :--- |
|[Pattern-Exploiting Training (PET)](https://github.com/timoschick/pet)|This repository contains the code for [Exploiting Cloze Questions for Few-Shot Text Classification and Natural Language Inference](https://arxiv.org/abs/2001.07676) and [It's Not Just Size That Matters: Small Language Models Are Also Few-Shot Learners](https://arxiv.org/abs/2009.07118). The papers introduce pattern-exploiting training (PET), a semi-supervised training procedure that reformulates input examples as cloze-style phrases. In low-resource settings, PET and iPET significantly outperform regular supervised training, various semi-supervised baselines and even GPT-3 despite requiring 99.9% less parameters. The iterative variant of PET (iPET) trains multiple generations of models and can even be used without any training data.|

## Python packages

| Title | Description |
| :---:         |          :--- |
|[PySS3](https://github.com/sergioburdisso/pyss3)|SS3 text classifier is a novel and simple supervised machine learning model for text classification which is interpretable, that is, it has the ability to naturally (self)explain its rationale.|
