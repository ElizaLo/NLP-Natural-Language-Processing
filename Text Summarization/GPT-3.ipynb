{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT-3 - Generative Pre-trained Transformer 3\n",
    "\n",
    "**Paper:** [Language Models are Few-Shot Learners](https://arxiv.org/abs/2005.14165)\n",
    "\n",
    "Papers with Code: [GPT-3](https://paperswithcode.com/method/gpt-3)\n",
    "\n",
    "[Open AI Documentation](https://beta.openai.com/docs/models/gpt-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U boto3 awswrangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import sagemaker\n",
    "import awswrangler as wr\n",
    "import openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up Open AI `OPENAI_API_KEY`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = ('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = sagemaker.get_execution_role()\n",
    "data_location = 's3://datasets/text_summarization/corpus/corpus.csv'\n",
    "\n",
    "df = pd.DataFrame(pd.read_csv(data_location))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chosing texts with `<= 2000` words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_optimal = df[df['LENGHT'] == 'OPTIMAL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_optimal.shape)\n",
    "df_optimal.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the functions with Open AI applications:\n",
    "\n",
    "- Summarize for a 2nd grader\n",
    "- TL;DR summarization\n",
    "- Keywords\n",
    "- Notes to summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize for a 2nd grader\n",
    "def second_grader_summarization(text):\n",
    "    response = openai.Completion.create(\n",
    "        model=\"text-davinci-003\",\n",
    "        prompt=\"Summarize this for a second-grade student:\\n\\n{}.\\n\\n\".format(text),\n",
    "        temperature=0.7,\n",
    "        max_tokens=600,\n",
    "        top_p=1.0,\n",
    "        frequency_penalty=0.0,\n",
    "        presence_penalty=0.0\n",
    "    )\n",
    "    return response['choices'][0]['text']\n",
    "\n",
    "\n",
    "# TL;DR summarization\n",
    "def Tl_dr_summarization(text):\n",
    "    response_Tl_dr = openai.Completion.create(\n",
    "        model=\"text-davinci-003\",\n",
    "        prompt=\"{}\\n\\nTl;dr\\n\\n\".format(text),\n",
    "        temperature=0.7,\n",
    "        max_tokens=600,\n",
    "        top_p=1.0,\n",
    "        frequency_penalty=0.0,\n",
    "        presence_penalty=0.0\n",
    "    )\n",
    "    return response_Tl_dr['choices'][0]['text']\n",
    "\n",
    "\n",
    "# Keywords\n",
    "def keywords_extraction(text):\n",
    "    response_extract = openai.Completion.create(\n",
    "        model=\"text-davinci-003\",\n",
    "        prompt=\"Extract keywords from this text:\\n\\n{}\\n\\n\".format(text),\n",
    "        temperature=0.7,\n",
    "        max_tokens=600,\n",
    "        top_p=1.0,\n",
    "        frequency_penalty=0.8,\n",
    "        presence_penalty=0.0\n",
    "    )\n",
    "    return response_extract['choices'][0]['text']\n",
    "\n",
    "# Keywords\n",
    "def keywords_extraction_05(text):\n",
    "    response_extract = openai.Completion.create(\n",
    "        model=\"text-davinci-003\",\n",
    "        prompt=\"Extract keywords from this text:\\n\\n{}\\n\\n\".format(text),\n",
    "        temperature=0.5,\n",
    "        max_tokens=600,\n",
    "        top_p=1.0,\n",
    "        frequency_penalty=0.8,\n",
    "        presence_penalty=0.0\n",
    "    )\n",
    "    return response_extract['choices'][0]['text']\n",
    "\n",
    "\n",
    "# Notes to summary\n",
    "def notes2summary(text):\n",
    "    response_notes2summary = openai.Completion.create(\n",
    "        model=\"text-davinci-003\",\n",
    "        prompt=\"Convert my short hand into a first-hand account of the meeting:\\n\\n{}\\n\\n\".format(text),\n",
    "        temperature=0,\n",
    "        max_tokens=600,\n",
    "        top_p=1.0,\n",
    "        frequency_penalty=0.0,\n",
    "        presence_penalty=0.0\n",
    "    )\n",
    "    return response_notes2summary['choices'][0]['text']\n",
    "\n",
    "# Notes to summary\n",
    "def notes2summary_05(text):\n",
    "    response_notes2summary = openai.Completion.create(\n",
    "        model=\"text-davinci-003\",\n",
    "        prompt=\"Convert my short hand into a first-hand account of the meeting:\\n\\n{}\\n\\n\".format(text),\n",
    "        temperature=0.5,\n",
    "        max_tokens=600,\n",
    "        top_p=1.0,\n",
    "        frequency_penalty=0.0,\n",
    "        presence_penalty=0.0\n",
    "    )\n",
    "    return response_notes2summary['choices'][0]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calling Open AI API with GPT-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarized = pd.DataFrame()\n",
    "\n",
    "for i in range(110): #357\n",
    "    text = df_optimal['TEXT'].values[i]\n",
    "    \n",
    "    summarized.at[i, \"Original Text\"] = df_optimal['TEXT'].values[i]\n",
    "    \n",
    "    summarized.at[i, \"second_grader_summarization\"] = second_grader_summarization(text)\n",
    "    summarized.at[i, \"Tl_dr_summarization\"] = Tl_dr_summarization(text)\n",
    "    summarized.at[i, \"keywords_extraction_0.7\"] = keywords_extraction(text)\n",
    "    summarized.at[i, \"keywords_extraction_0.5\"] = keywords_extraction_05(text)\n",
    "    summarized.at[i, \"notes2summary_0\"] = notes2summary(text)\n",
    "    summarized.at[i, \"notes2summary_0.5\"] = notes2summary_05(text)\n",
    "    \n",
    "    summarized.at[i, \"Key\"] = df_optimal['KEY'].values[i]\n",
    "    summarized.at[i, \"Filename\"] = df_optimal['FILENAME'].values[i]\n",
    "    summarized.at[i, \"NUM_WORDS\"] = df_optimal['NUM_WORDS'].values[i]\n",
    "    summarized.at[i, \"NUM_WORDS_ROUNDED\"] = df_optimal['NUM_WORDS_ROUNDED'].values[i]\n",
    "    \n",
    "    if i % 5 == 0:\n",
    "        wr.s3.to_csv(\n",
    "            df=summarized,\n",
    "            path='s3://datasets/text_summarization/summarized/GPT-3_text-davinci-003/GPT-3_text-davinci-003.csv'\n",
    "        )\n",
    "        print(i)\n",
    "\n",
    "    \n",
    "summarized    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarized = summarized.replace('\\n',' ', regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wr.s3.to_csv(\n",
    "            df=summarized,\n",
    "            path='s3://datasets/text_summarization/summarized/GPT-3_text-davinci-003/GPT-3_text-davinci-003.csv'\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark>Input texts examples:</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text = '''Hawaii comprises nearly the entire Hawaiian archipelago, 137 volcanic islands spanning 1,500 miles (2,400 km) that are physiographically and ethnologically part of the Polynesian subregion of Oceania. The state's ocean coastline is consequently the fourth-longest in the U.S., at about 750 miles (1,210 km).[b] The eight main islands, from northwest to southeast, are Niʻihau, Kauaʻi, Oʻahu, Molokaʻi, Lānaʻi, Kahoʻolawe, Maui, and Hawaiʻi—the last of these, after which the state is named, is often called the \"Big Island\" or \"Hawaii Island\" to avoid confusion with the state or archipelago. The uninhabited Northwestern Hawaiian Islands make up most of the Papahānaumokuākea Marine National Monument, the United States' largest protected area and the fourth-largest in the world. Of the 50 U.S. states, Hawaii is the eighth-smallest in land area and the 11th-least populous, but with 1.4 million residents ranks 13th in population density. Two-thirds of the population lives on O'ahu, home to the state's capital and largest city, Honolulu. Hawaii is among the country's most diverse states, owing to its central location in the Pacific and over two centuries of migration. As one of only six majority-minority states, it has the country's only Asian American plurality, its largest Buddhist community, and the largest proportion of multiracial people. Consequently, it is a unique melting pot of North American and East Asian cultures, in addition to its indigenous Hawaiian heritage. Settled by Polynesians some time between 1000 and 1200 CE, Hawaii was home to numerous independent chiefdoms. In 1778, British explorer James Cook was the first known non-Polynesian to arrive at the archipelago; early British influence is reflected in the state flag, which bears a Union Jack. An influx of European and American explorers, traders, and whalers arrived shortly after leading to the decimation of the once isolated Indigenous community by introducing diseases such as syphilis, gonorrhea, tuberculosis, smallpox, measles, leprosy, and typhoid fever, reducing the native Hawaiian population from between 300,000 and one million to less than 40,000 by 1890. Hawaii became a unified, internationally recognized kingdom in 1810, remaining independent until American and European businessmen overthrew the monarchy in 1893; this led to annexation by the U.S. in 1898. As a strategically valuable U.S. territory, Hawaii was attacked by Japan on December 7, 1941, which brought it global and historical significance, and contributed to America's decisive entry into World War II. Hawaii is the most recent state to join the union, on August 21, 1959. In 1993, the U.S. government formally apologized for its role in the overthrow of Hawaii's government, which spurred the Hawaiian sovereignty movement.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize for a 2nd grader\n",
    "\n",
    "> Translates difficult text into simpler concepts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "    model=\"text-davinci-003\",\n",
    "    #prompt=text,\n",
    "    prompt=\"Summarize this for a second-grade student:\\n\\n{}\\n\\n\".format(text),\n",
    "    temperature=0.7,\n",
    "    max_tokens=554,\n",
    "    top_p=1.0,\n",
    "    frequency_penalty=0.0,\n",
    "    presence_penalty=0.0\n",
    ")\n",
    "\n",
    "response['choices'][0]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TL;DR summarization\n",
    "\n",
    "> Summarize text by adding a `'tl;dr:'` to the end of a text passage. It shows that the API understands how to perform a number of tasks with no instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_Tl_dr = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"{}\\n\\nTl;dr\\n\\n\".format(text),\n",
    "  temperature=0.7,\n",
    "  max_tokens=554,\n",
    "  top_p=1.0,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0\n",
    ")\n",
    "\n",
    "response_Tl_dr['choices'][0]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keywords\n",
    "\n",
    "> Extract keywords from a block of text. At a lower temperature it picks keywords from the text. At a higher temperature it will generate related keywords which can be helpful for creating search indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_extract = openai.Completion.create(\n",
    "    model=\"text-davinci-002\",\n",
    "    prompt=\"Extract keywords from this text:\\n\\n{}\\n\\n\".format(text),\n",
    "    temperature=0.3,\n",
    "    max_tokens=1024,\n",
    "    top_p=1.0,\n",
    "    frequency_penalty=0.8,\n",
    "    presence_penalty=0.0\n",
    ")\n",
    "\n",
    "response_extract['choices'][0]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes to summary\n",
    "\n",
    "> Notes to summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_notes2summary = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"Convert my short hand into a first-hand account of the meeting:\\n\\n{}\\n\\n\".format(text),\n",
    "  temperature=0.7,\n",
    "  max_tokens=600,\n",
    "  top_p=1.0,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0\n",
    ")\n",
    "\n",
    "response_notes2summary['choices'][0]['text']"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
