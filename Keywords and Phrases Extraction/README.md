# Keywords and Phrases Extraction

## Models

| Title | Description, Information |
| :---:         |          :--- |
| **GPT-3** | ğŸ“„ **Paper:** [Language Models are Few-Shot Learners](https://arxiv.org/abs/2005.14165v4), [News Summarization and Evaluation in the Era of GPT-3](https://arxiv.org/pdf/2209.12356.pdf), [Papers with Code - GPT-3 Explained](https://paperswithcode.com/method/gpt-3)|

### ğŸ”¹ GPT-3: Generative Pre-trained Transformer

- ğŸ“„ **Paper:** [Language Models are Few-Shot Learners](https://arxiv.org/abs/2005.14165)
  - ğŸ“ƒ Other related papers: [News Summarization and Evaluation in the Era of GPT-3](https://arxiv.org/abs/2209.12356)
  - [Papers with Code - GPT-3 Explained](https://paperswithcode.com/method/gpt-3)
- :hammer_and_wrench: **Implementations:**
  - [OpenAI API - GPT-3 Documentation](https://beta.openai.com/docs/models/gpt-3)
  - [Fine-tuning](https://beta.openai.com/docs/guides/fine-tuning)
- ğŸ“° **Articles:**
  - [State of the Art GPT-3 Summarizer For Any Size Document or Format](https://www.width.ai/post/gpt3-summarizer)
- :gear: **Notebook:** 
  - [GPT-3.ipynb](https://github.com/ElizaLo/NLP-Natural-Language-Processing/blob/master/Text%20Summarization/GPT-3.ipynb) - GPT-3 - Generative Pre-trained Transformer 3, **_model_**: `text-davinci-003` (released: _November 2022_) 

#### GPT-3 Tokenization

- [GPT-3 Online Tokenizer](https://beta.openai.com/tokenizer)

Tokenizer for GPT-3 is the same as GPT-2: ğŸ¤— [OpenAI GPT2](https://huggingface.co/docs/transformers/model_doc/gpt2#gpt2tokenizerfast).

A helpful rule of thumb is that one token generally corresponds to ~4 characters of text for common English text. This translates to roughly Â¾ of a word (so 100 tokens ~= 75 words).

The GPT-3 model can take as input from 4,000 to 2,000 tokens (**not confused with words!**). GPT-3 generates ~125-140% tokenks from the input text). 
> The text with 2,000 words approximately has 2,800 tokens.

Models understand and process text by breaking it down into tokens. Tokens can be words or just chunks of characters. For example, the word _**â€œhamburgerâ€**_ gets broken up into the tokens _**â€œhamâ€**_, _**â€œburâ€**_ and _**â€œgerâ€**_, while a short and common word like _**â€œpearâ€**_ is a single token. Many tokens start with a whitespace, for example _**â€œ helloâ€**_ and _**â€œ byeâ€**_.

<img src="https://raw.githubusercontent.com/ElizaLo/NLP-Natural-Language-Processing/master/Language%20Models/img/tokens.png" width="726" height="96"/>

> Common words like _**â€œcatâ€**_ are a single token, while less common words are often broken down into multiple tokens. _For example,_ _**â€œButterscotchâ€**_ translates to four tokens: _**â€œButâ€**_, _**â€œtersâ€**_, _**â€œcotâ€**_, and _**â€œchâ€**_.

The number of tokens processed in a given API request depends on the length of both your inputs and outputs. As a rough rule of thumb, 1 token is approximately 4 characters or 0.75 words for English text. One limitation to keep in mind is that your text prompt and generated completion combined must be no more than the model's maximum context length (for most models this is 2048 tokens, or about 1500 words). Check out [tokenizer tool](https://beta.openai.com/tokenizer) to learn more about how text translates to tokens.

#### `text-davinci-003` model

> OpenAI releases a new language model for GPT-3 trained with human feedback (**November 2022**). It brings numerous improvements, according to OpenAI.

The new GPT-3 model `â€œtext-davinci-003â€` is based on the [InstructGPT](https://the-decoder.com/openai-million-dollar-investment-and-a-new-ai-model/) models introduced by OpenAI earlier this year, which are optimized with human feedback. These models have already shown that AI models trained with RLHF (Reinforcement Learning from Human Feedback) can achieve better results with the same or even lower parameters.

According to OpenAI alignment researcher Jan Leike, `â€œtext-davinci-003â€` is largely equivalent to the InstructGPT models, but is not identical. The new model â€œscores higher on human preference ratings without being fundamentally more capableâ€ than the underlying base model. For fine-tuning, OpenAI required â€œvery little compute and data to align it compared to pretrainingâ€.

Leike points out that the new GPT model still has â€œimportant limitationsâ€ and, for example, sometimes simply makes up things. However, such missteps should now â€œhopefullyâ€ be less frequent and less serious.

`â€œtext-davinci-003â€` can generate **â€œclearer, more engaging, and more compelling contentâ€** and handle **more complex instructions**, according to OpenAI.

`â€œtext-davinci-003â€` can also write longer texts, according to OpenAI. As a result, the language AI can now take on tasks that were previously unfeasible. 

ğŸ“° **Articles:**

- [OpenAIâ€™s latest GPT-3 model generates better and longer texts](https://the-decoder.com/openais-latest-gpt-3-model-generates-better-and-longer-texts/)

####  âš™ï¸ Fine-tuning model

- ğŸ”¸ **Change prompt**

From â†’ `Extract keywords from this text:`, to â†’ `Extract keywords and key phrases from this text:`

ğŸ’  **Prompt Design**

This simple text-in, text-out interface means you can "program" the model by providing instructions or just a few examples of what you'd like it to do. Its success generally depends on the complexity of the task and the quality of your prompt. A good rule of thumb is to think about how you would write a word problem for a middle schooler to solve. A well-written prompt provides enough information for the model to know what you want and how it should respond.

GPT-3 models by OpenAI can do everything from generating original stories to performing complex text analysis. Because they can do so many things, you have to be explicit in describing what you want. Showing, not just telling, is often the secret to a good prompt.

**There are basic guidelines to creating prompts:**

- **Show and tell.** Make it clear what you want either through instructions, examples, or a combination of the two. If you want the model to rank a list of items in alphabetical order or to classify a paragraph by sentiment, show it that's what you want. 
- **Use plain language to describe your inputs and outputs.** As a best practice, start with plain language descriptions. While you can often use shorthand or keys to indicate the input and output, it's best to start by being as descriptive as possible and then working backwards to remove extra words and see if performance stays consistent
- **Provide quality data.** If you're trying to build a classifier or get the model to follow a pattern, make sure that there are enough examples. Be sure to proofread your examples â€” the model is usually smart enough to see through basic spelling mistakes and give you a response, but it also might assume this is intentional and it can affect the response. â†’ thatâ€™s why you may need text pre-processing/cleaning and Grammatical Error Correction (GEC).
- **You need fewer examples for familiar tasks.** For Tweet sentiment classifier, you don't need to provide any examples. This is because the API already has an understanding of sentiment and the concept of a Tweet. If you're building a classifier for something the API might not be familiar with, it might be necessary to provide more examples.
- **Check your settings.** The `temperature` and `top_p` settings control how deterministic the model is in generating a response. If you're asking it for a response where there's only one right answer, then you'd want to set these lower. If you're looking for more diverse responses, then you might want to set them higher. The number one mistake people use with these settings is assuming that they're "cleverness" or "creativity" controls.

â€¼ï¸ **Troubleshooting**

If you're having trouble getting the API to perform as expected, follow this checklist:
1. Is it clear what the intended generation should be?
2. Are there enough examples?
3. Did you check your examples for mistakes? (The API won't tell you directly)
4. Are you using `temperature`` and top_p` correctly?

- ğŸ”¸ **Temperature**

> See more details and examples in ğŸ“‚ [Language Models](https://github.com/ElizaLo/NLP-Natural-Language-Processing/tree/master/Language%20Models#fine-tuning-model) folder

Remember that the model predicts which text is most likely to follow the text preceding it. Temperature is a value between 0 and 1 that essentially lets you control how confident the model should be when making these predictions. Lowering temperature means it will take fewer risks, and completions will be more accurate and deterministic. Increasing temperature will result in more diverse completions.

Itâ€™s usually best to set a low temperature for tasks where the desired output is well-defined. Higher temperature may be useful for tasks where variety or creativity are desired, or if you'd like to generate a few variations for your end users or human experts to choose from.

â€¼ï¸ The actual completion you see may differ because the API is stochastic by default. This means that you might get a slightly different completion every time you call it, even if your prompt stays the same. You can control this behavior with the [temperature](https://beta.openai.com/docs/api-reference/completions/create#completions/create-temperature) setting.

ğŸ“° **Articles**

- []()

#### ğŸ”º Evaluation Metrics

- NDCG (Normalized Discounted Cumulative Gain) 
- MRR (Mean Reciprocal Rank) 
- F1
- MAP (Mean Average Precision)

#### ğŸ’­ Conclusions

- The same `temperature` value generated different amounts of words and different words and phrases.
- This model is very sensitive to the input end, which influences the tokenization and consequently affects the extracted keywords.
    > **Warning:** Your text ends in a trailing space, which causes worse performance due to how the API splits text into tokens.
- Itâ€™s also worth taking note of the rather high `temperature` value and shorter max tokens. 
- Each time model generates text of different lengths. Setting up `max_tokens` doesnâ€™t guarantee that text would be this length.
- Words in upper case are divided wrong into the tokens (e.g. FEBRUARY, CUISINE, RESEARCH, MENU, etc.). It is necessary to reduce all words to lowercase or to the form of ordinary sentences, where only the capital letter in the word is large.

#### ğŸ’¡ Ideas

- Run the model with different `temperature` values and join results together to achieve more extracted keywords. 
- Run the model with different `temperature` values and count how many words are generated with each.
- Reduce all words to lowercase or to the form of ordinary sentences, where only the capital letter in the word is large.
- Clean texts to make them more structured and coherent.
- **Chunk/divide the input text:** divide the text into several smaller ones and make a keywords extraction for each of them separately and then combine it into one concatenated keywords list.
- Make chunking of documents, try and compare the results of summarization of **different GPT-3 models**: `text-davinci-003`, `text-curie-001`, `text-babbage-001` and `text-ada-001`.

#### â“ Questions

- How to evaluate results?
- How to choose `temperature` value?
