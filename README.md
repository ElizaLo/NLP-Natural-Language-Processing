<img src="https://github.com/ElizaLo/NLP-Natural-Language-Processing/blob/master/img/NLP_Banner.png" width="900" height="150">

[![Hits](https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fgithub.com%2FElizaLo%2FNLP-Natural-Language-Processing&count_bg=%23027A06&title_bg=%23A7A7B0&icon=python.svg&icon_color=%23E7E7E7&title=Repository+Views&edge_flat=false)](https://hits.seeyoufarm.com)

### Constantly updated. Subscribe not to miss anything.

> - [ ] For full **Data Science**  tasks, materials, etc. please check [Data Science](https://github.com/ElizaLo/Data-Science) repository.

> - [ ] For **Machine Learning**  algorithms please check [Machine Learning](https://github.com/ElizaLo/Machine-Learning) repository.

> - [ ] For **Deep Learning** algorithms please check [Deep Learning](https://github.com/ElizaLo/Deep-Learning) repository.

> - [ ] For **Computer Vision** please check [Computer Vision](https://github.com/ElizaLo/Computer-Vision) repository.

-----

- [NLP-progress](https://nlpprogress.com) - Repository to track the progress in Natural Language Processing (NLP), including the datasets and the current state-of-the-art for the most common NLP tasks.
  - :octocat: [Tracking Progress in Natural Language Processing](https://github.com/sebastianruder/NLP-progress)

# üí† Natural Language Processing Tasks 

> Folders with all materials for specific task/domain

- [Data Analysis](https://github.com/ElizaLo/NLP-Natural-Language-Processing/tree/master/Data%20Analysis)
- [Knowledge Graph](https://github.com/ElizaLo/NLP-Natural-Language-Processing/tree/master/Knowledge%20Graph)
- [Models and Algorithms](https://github.com/ElizaLo/NLP-Natural-Language-Processing/tree/master/Models%20and%20Algorithms)
- [Ontologies](https://github.com/ElizaLo/NLP-Natural-Language-Processing/tree/master/Ontologies)
- [Question Answering System](https://github.com/ElizaLo/NLP-Natural-Language-Processing/tree/master/Question%20Answering%20System)
- [Search Engine](https://github.com/ElizaLo/NLP-Natural-Language-Processing/tree/master/Search%20Engine)
- [Sentiment Analysis](https://github.com/ElizaLo/NLP-Natural-Language-Processing/tree/master/Sentiment%20Analysis)
- [Shallow Discourse Parsing](https://github.com/ElizaLo/NLP-Natural-Language-Processing/tree/master/Shallow%20Discourse%20Parsing)
- [Text Classification](https://github.com/ElizaLo/NLP-Natural-Language-Processing/tree/master/Text%20Classification%20)
- [Topic Modeling](https://github.com/ElizaLo/NLP-Natural-Language-Processing/tree/master/Topic%20Modeling)
- [Word Embedings](https://github.com/ElizaLo/NLP-Natural-Language-Processing/tree/master/Word%20Embedings)


# üéì Courses 

  - [Natural Language Processing - Stanford University| Dan Jurafsky, Christopher](https://www.youtube.com/playlist?list=PLLssT5z_DsK8HbD2sPcUIDfQ7zmBarMYv)
  - [Natural Language Processing with Deep Learning (Stanford CS224N)](https://www.youtube.com/playlist?list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z) 
     - [Course website](http://web.stanford.edu/class/cs224n/)
     - [Stanford CS224N: Natural Language Processing with Deep Learning | Winter 2021](https://www.youtube.com/playlist?list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ) 
     - [Natural Language Processing with Dan Jurafsky and Chris Manning, 2012 Stanford Online](https://www.youtube.com/playlist?list=PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ)
     > Modern NLP techniques from recurrent neural networks and word embeddings to transformers and self-attention. Covers applied topics like questions answering and text generation.
  - [Stanford CS224U: Natural Language Understanding | Spring 2019](https://www.youtube.com/playlist?list=PLoROMvodv4rObpMCir6rNNUlFAn56Js20)
  - [Natural Language Processing | University of Michigan](https://www.youtube.com/playlist?list=PLLssT5z_DsK8BdawOVCCaTCO99Ya58ryR)
  - :octocat: [A Code-First Introduction to NLP course](https://github.com/fastai/course-nlp) by fast.ai
  - [From Languages to Information](https://web.stanford.edu/class/cs124/) by Stanford University
  - [Deep Learning for Natural Language Processing](https://www.cs.ox.ac.uk/teaching/courses/2016-2017/dl/) by University of Oxford
  - [Natural Language Processing](https://courses.cs.washington.edu/courses/cse517/17wi/) by University of Washington
  - [Natural Language Processing](https://github.com/yandexdataschool/nlp_course) by Yandex Data School
    - [NLP Course | For You](https://lena-voita.github.io/nlp_course.html)
    > This is an extension to the (ML for) Natural Language Processing course teached at the Yandex School of Data Analysis (YSDA). For now, only part of the topics is likely to be covered here.
  - [Natural Language Processing](https://www.coursera.org/learn/language-processing) by National Research University Higher School of Economics (via Coursera)
  - [Applied Natural Language Processing](http://people.ischool.berkeley.edu/~dbamman/info256.html) by UC Berkeley
  - [Advanced Methods in Natural Language Processing](https://www.cs.tau.ac.il/~joberant/teaching/nlp_spring_2019/index.html) by Tel Aviv University
  - [Text Retrieval and Search Engines [FULL COURSE] | UIUC](https://www.youtube.com/playlist?list=PLLssT5z_DsK8Jk8mpFc_RPzn2obhotfDO)
    > This course will cover search engine technologies, which play an important role in any data mining applications involving text data for two reasons. First, while the raw data may be large for any particular problem, it is often a relatively small subset of the data that are relevant, and a search engine is an essential tool for quickly discovering a small subset of relevant text data in a large text collection. Second, search engines are needed to help analysts interpret any patterns discovered in the data by allowing them to examine the relevant original text data to make sense of any discovered pattern. You will learn the basic concepts, principles, and the major techniques in text retrieval, which is the underlying science of search engines. 
  - [Text Mining and Analytics [FULL COURSE] | UIUC](https://www.youtube.com/playlist?list=PLLssT5z_DsK8Xwnh_0bjN4KNT81bekvtt)
  - [Mining Massive Datasets - Stanford University [FULL COURSE]](https://www.youtube.com/playlist?list=PLLssT5z_DsK9JDLcT8T62VtzwyW9LNepV)
  - Coursera:
    - [–°–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤, –Ω–∞–ø–∏—Å–∞–Ω–Ω—ã—Ö –Ω–∞ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —è–∑—ã–∫–∞—Ö](https://www.coursera.org/specializations/natural-language-processing?utm_source=deeplearningai&utm_medium=institutions&utm_content=NLP_6/17_ppt#howItWorks)
    - [Text Mining](https://www.coursera.org/learn/text-mining) (–ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–æ–≤–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏ –∞–Ω–∞–ª–∏—Ç–∏–∫–∞)
  - LinkedIn Learning:
    - [Advanced NLP with Python for Machine Learning](https://www.linkedin.com/learning/advanced-nlp-with-python-for-machine-learning)
      - Folder with [code](https://github.com/ElizaLo/NLP-Natural-Language-Processing/blob/master/Courses/LinkedIn%20Learning/Advanced%20NLP%20with%20Python%20for%20Machine%20Learning/Exercises.ipynb)
  - :octocat: [–ú–∞—Ç–µ—Ä—ñ–∞–ª–∏ –¥–ª—è –∫—É—Ä—Å—É NLP –≤ –ü—Ä–æ–¥–∂–µ–∫—Ç–æ—Ä—ñ](https://github.com/sudodoki/prj-nlp/tree/master)
  - [Advaced NLP with spaCy](https://course.spacy.io/en/)
  - [fast.ai course: A Code-First Introduction to Natural Language Processing](https://www.fast.ai/posts/2019-07-08-fastai-nlp.html) 
    - :octocat: [A Code-First Intro to Natural Language Processing](https://github.com/fastai/course-nlp) on GitHub :octocat:
  - :octocat: [CS 4650 and 7650](https://github.com/jacobeisenstein/gt-nlp-class) - Course materials for Georgia Tech CS 4650 and 7650, "Natural Language"
  
# üìö Books

- [A lot of NLP books](https://www.dropbox.com/sh/b1c2ulwua9zy574/AACswS1E0IB9LdPDxQ6fexm4a?dl=0) (Natural Language Processing)
- [Advanced Natural Language Processing with TensorFlow 2](https://github.com/PacktPublishing/Advanced-Natural-Language-Processing-with-TensorFlow-2), published by Packt
- [Natural Language Processing with Python ‚Äì Analyzing Text with the Natural Language Toolkit](http://www.nltk.org/book/), Steven Bird, Ewan Klein, and Edward Loper
- [Speech and Language Processing (3rd ed. draft)](https://web.stanford.edu/~jurafsky/slp3/), Dan Jurafsky and James H. Martin
- [Neural Network Methods for Natural Language Processing](http://www.morganclaypoolpublishers.com/catalog_Orig/samples/9781627052955_sample.pdf)
- [Natural Language Processing with Python ‚Äì Analyzing Text with the Natural Language Toolkit](http://www.nltk.org/book/)
  - [NLTK_book](https://github.com/nltk/nltk_book) on GitHub
- [Practical Natural Language Processing](https://github.com/practical-nlp/practical-nlp-code)
  - > Official Repository for **'Practical Natural Language Processing'** by _O'Reilly Media_
- [Natural Language Processing Notebooks](https://github.com/NirantK/NLP_Quickbook)
  - > Available as a Book: [NLP in Python - Quickstart Guide](https://www.amazon.in/dp/B07L3PLQS1)
- 

# üé• YouTube 

| Title | Description |
| :---         |          :--- |
|[ACL](https://vimeo.com/aclweb)| at Vimeo|
| [Stanford CS224N: Natural Language Processing with Deep Learning | Winter 2021](https://www.youtube.com/playlist?list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ) |  |
|[Natural Language Processing (NLP) Zero to Hero](https://www.youtube.com/playlist?list=PLQY2H8rRoyvzDbLUZkbudP-MFQZwNmU4S)| by TensorFlow|
|[Zero to Hero: NLP with Tensorflow and Keras (GDG Sofia meetup)](https://www.youtube.com/watch?v=ECRUJTKuKKs)| |
|[Natural Language Processing](https://www.youtube.com/playlist?list=PL8P_Z6C4GcuWfAq8Pt6PBYlck4OprHXsw)|This content is based on Machine Learning University (MLU) Accelerated Natural Language Processing class. Slides, notebooks and datasets are available on [GitHub](https://github.com/aws-samples/aws-machine-learning-university-accelerated-nlp)|

# üñ•Ô∏è Web Sites

- [Natural Language Processing](https://paperswithcode.com/area/natural-language-processing) on Papers with Code
- [Chris McCormick](https://mccormickml.com) Blog
  - [ChrisMcCormickAI](https://www.youtube.com/channel/UCoRX98PLOsaN8PtekB9kWrw/videos) YouTube Channel
- [The NLP Index](https://index.quantumstat.com)
- [Sebastian Ruder](https://ruder.io)
  - > I'm a research scientist at Google. I blog about natural language processing and machine learning.  
- :octocat: [Software Engineering Blogs](https://github.com/kilimchoi/engineering-blogs)
  - > A curated list of engineering blogs
- [The Gradient](https://thegradient.pub)
  - > The Gradient is an organization with the missions of making it easier for anyone to learn about AI and of facilitating discussion within the AI community. We were founded in 2017 by a group of students and researchers at the Stanford AI Lab.
-

# üì∞ Atricles

- [–ö–∞—Ä—å–µ—Ä–∞ –≤ IT: NLP Engineer –∏ NLP Researcher](https://dou.ua/lenta/articles/nlp-specialist/?from=tg)

# :octocat: GitHub Repositories

| Title | Description |
| :---:         |          :--- |
|[NVIDIA Deep Learning Examples for Tensor Cores - Natural Language Processing](https://github.com/NVIDIA/DeepLearningExamples#natural-language-processing)|Deep Learning Examples|
|[Natural Language Processing with Transformers](https://github.com/nlp-with-transformers)|Notebooks and materials for the O'Reilly book ["Natural Language Processing with Transformers"](https://learning.oreilly.com/library/view/natural-language-processing/9781098103231/)|
|[Awesome NLP References](https://github.com/JudePark96/awesome-nlp-references)|A curated list of resources dedicated to Knowledge Distillation, Recommendation System, especially Natural Language Processing (NLP)|
|[NLP - Tutorial](https://github.com/makcedward/nlp)| |
|[Natural Language-Process Tutorials](https://github.com/skuchkula/Natural-Language-Processing-Tutorials)| |
|[NLP with Python](https://github.com/susanli2016/NLP-with-Python)|Scikit-Learn, NLTK, Spacy, Gensim, Textblob and more...|
|[NLP and Data Science GitHub Repository Spotlight](https://github.com/ivan-bilan/NLP-and-Data-Science-Spotlights)|Daily spotlights of some underrated NLP and Data Science GitHub repositories.|
|[NLP 101: a Resource Repository for Deep Learning and Natural Language Processing](https://github.com/Huffon/NLP101)|This document is drafted for those who have enthusiasm for Deep Learning in natural language processing. If there are any good recommendations or suggestions, I will try to add more.|
|[NLP-progress](https://github.com/sebastianruder/NLP-progress)|Repository to track the progress in Natural Language Processing (NLP), including the datasets and the current state-of-the-art for the most common NLP tasks.|
|[Hugging Face](https://github.com/huggingface/blog)|Public repo for HF blog posts|
|[AllenNLP](https://github.com/allenai/allennlp)|An open-source NLP research library, built on PyTorch. [Allenai.org](https://allenai.org/allennlp)|

# üó£Ô∏è Conferences

- [NeurIPS](https://nips.cc) - Neural Information Processing Systems
- [ACL](https://www.aclweb.org/portal/) - ACL Home Association for Computational Linguistics
  - [ACL Anthology](https://aclanthology.org) - The ACL Anthology currently hosts 80890 papers on the study of computational linguistics and natural language processing.
- 

# üõ†Ô∏è Tools

> NLP libraries, frameworks, modules

| Title | Description |
| :---:         |          :--- |
|[Natural Language Toolkit (NLTK)](https://github.com/nltk/nltk)|NLTK - the Natural Language Toolkit - is a suite of open source Python modules, data sets, and tutorials supporting research and development in Natural Language Processing.|
|[flair](https://github.com/flairNLP/flair)|<ul><p>A very simple framework for state-of-the-art Natural Language Processing (NLP).</p><p>Flair is:</p><li>**A powerful NLP library.** Flair allows you to apply our state-of-the-art natural language processing (NLP) models to your text, such as **named entity recognition (NER), part-of-speech tagging (PoS), special support for biomedical data, sense disambiguation and classification**, with support for a rapidly growing number of languages.</li><li>**A text embedding library.** Flair has simple interfaces that allow you to use and combine different word and document embeddings, including our proposed Flair embeddings, BERT embeddings and ELMo embeddings.</li><li>**A PyTorch NLP framework.** Our framework builds directly on PyTorch, making it easy to train your own models and experiment with new approaches using Flair embeddings and classes.</li></ul>|
|[textacy](https://github.com/chartbeat-labs/textacy)|`textacy` is a Python library for performing a variety of natural language processing (NLP) tasks, built on the high-performance spaCy library. With the fundamentals --- tokenization, part-of-speech tagging, dependency parsing, etc. --- delegated to another library, `textacy` focuses primarily on the tasks that come before and follow after.|
|[AllenNLP](https://github.com/allenai/allennlp)|NLP research library, built on PyTorch, for developing state-of-the-art deep learning models on a wide variety of linguistic tasks.|
|[NLPGym](https://github.com/rajcscw/nlp-gym)|NLPGym is a toolkit to bridge the gap between applications of RL and NLP. This aims at facilitating research and benchmarking of DRL application on natural language processing tasks. The toolkit provides interactive environments for standard NLP tasks such as sequence tagging, question answering, and sequence classification.|
|[Gensim](https://radimrehurek.com/gensim/index.html)||

# üë©üèª‚Äçüè´ Tutorials

| Title | Description |
| :---:         |          :--- |
|[nlp-tutorial](https://github.com/graykode/nlp-tutorial)|<ul><p>Natural Language Processing Tutorial for Deep Learning Researchers</p><p>`nlp-tutorial` is a tutorial for who is studying NLP(Natural Language Processing) using **Pytorch**. Most of the models in NLP were implemented with less than 100 lines of code.(except comments or blank lines)</p></ul>|
|[Natural Language Processing in Python Tutorial](https://github.com/adashofdata/nlp-in-python-tutorial)|comparing stand up comedians using natural language processing|


# üîù Leaderboard for NLP

- [ExplainaBoard: An Explainable Leaderboard for NLP](https://github.com/neulab/ExplainaBoard)

# üí† Deep Learning architectures for NLP

- [Introduction to Deep Learning for Natural Language Processing](https://github.com/rouseguy/europython2016_dl-nlp)
- [Deep Learning architectures for NLP](https://github.com/Tixierae/deep_learning_NLP) - Keras, PyTorch, and NumPy Implementations of Deep Learning Architectures for NLP

üîπ [100 Must-Read NLP Papers](http://masatohagiwara.net/100-nlp-papers/)

üîπ [Sci-Hub(Papers)](https://sci-hub.tw)

üîπ [Stanford, NLP Seminar Schedule](https://nlp.stanford.edu/seminar/)

üîπ [CS224n: Natural Language Processing with Deep Learning](http://web.stanford.edu/class/cs224n/)

üîπ [CIS 700-008 - Interactive Fiction and Text Generation](http://interactive-fiction-class.org/)

üîπ [Harvard NLP](http://nlp.seas.harvard.edu)

üîπ [The Illustrated Transformer](http://jalammar.github.io/illustrated-transformer/)

-------------------------------------------------------

# üî∫ Projects

- [**_Spam Detection_**](https://github.com/ElizaLo/ML-with-Jupiter#spam-detection)
- [**_Text Generator_**](https://github.com/ElizaLo/ML-with-Jupiter#text-generator)
- [**_Question Answering System using BiDAF Model on SQuAD_**](https://github.com/ElizaLo/Question-Answering-based-on-SQuAD)

## Question Answering System using BiDAF Model on SQuAD

Implemented a Bidirectional Attention Flow neural network as a baseline on SQuAD, improving Chris Chute's model [implementation](https://github.com/chrischute/squad/blob/master/layers.py), adding word-character inputs as described in the original paper and improving [GauthierDmns' code](https://github.com/GauthierDmn/question_answering).

  - [Project Repository](https://github.com/ElizaLo/Question-Answering-based-on-SQuAD)
  - [Paper](https://github.com/ElizaLo/NLP/blob/master/Question%20Answering%20System/Question%20Answering%20System%20based%20on%20SQuAD.pdf)
  - [Used Articles](https://github.com/ElizaLo/NLP/tree/master/Question%20Answering%20System/Articles)
  - [Useful Articles](https://github.com/ElizaLo/Question-Answering-based-on-SQuAD#useful-articles)
  - [Useful Links](https://github.com/ElizaLo/Question-Answering-based-on-SQuAD#useful-links)
  
  # Useful Articles
  
  - [Interpretation of Natural Language Rules in Conversational Machine Reading](https://arxiv.org/abs/1809.01494)
  - [Skip-Thought Vectors](https://github.com/ElizaLo/NLP/blob/master/University%20Course%20of%20NLP/Articles/5950-skip-thought-vectors.pdf), [Article](https://arxiv.org/abs/1506.06726)
  
 # Some Concepts
 
 - [x] **Selectional Preference** - (Katz and Fodor, 1963; Wilks, 1975; Resnik, 1993) are the tendency for a word to semantically select or constrain which other words may appear in a direct syntactic relation with it." In case this selection is expressed in binary term (**_allowed/not-allowed_**), it is also called selectional restriction (S√©aghdha and Korhonen, 2014). SP can be contrasted with **_verb subcategorization_** "with subcategorization describing the syntactic arguments taken by a verb, and selectional preferences describing the semantic preferences verbs have for their arguments" (Van de Cruys et al., 2012)
    - [Selectional preference, Natural Language Understanding Wiki](https://natural-language-understanding.fandom.com/wiki/Selectional_preference)
 - [x] **Selectional Restrictions** - 
    - [Selectional Restrictions, Jurafsky](https://web.stanford.edu/~jurafsky/slp3/slides/22_select.pdf)
